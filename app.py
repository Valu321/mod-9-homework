import streamlit as st
import pandas as pd
import openai
import os
import json
import boto3
from botocore.client import Config
import io
from dotenv import load_dotenv
import pandera as pa
from pandera.errors import SchemaError
# Ostateczna, poprawna wersja importu
from langfuse import Langfuse
from pycaret.regression import load_model, predict_model

# Wczytaj zmienne ≈õrodowiskowe z pliku .env
load_dotenv()

# --- Konfiguracja ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LANGFUSE_PUBLIC_KEY = os.getenv("LANGFUSE_PUBLIC_KEY")
LANGFUSE_SECRET_KEY = os.getenv("LANGFUSE_SECRET_KEY")
DO_SPACES_KEY = os.getenv('DO_SPACES_KEY')
DO_SPACES_SECRET = os.getenv('DO_SPACES_SECRET')
DO_SPACES_ENDPOINT_URL = os.getenv('DO_SPACES_ENDPOINT_URL', 'https://fra1.digitaloceanspaces.com')
DO_SPACES_BUCKET = os.getenv('DO_SPACES_BUCKET')
MODEL_FILE_KEY = 'models/halfmarathon_pipeline.pkl'

# Inicjalizacja klient√≥w
if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

# Inicjalizacja Langfuse.
# Je≈õli klucze nie zostanƒÖ podane, obiekt nie zostanie utworzony.
langfuse = None
if LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY:
    langfuse = Langfuse(
        public_key=LANGFUSE_PUBLIC_KEY,
        secret_key=LANGFUSE_SECRET_KEY,
        host="https://cloud.langfuse.com"
    )

# --- Schemat walidacji Pandera ---
llm_output_schema = pa.DataFrameSchema({
    "wiek": pa.Column(int, checks=pa.Check.in_range(1, 100), nullable=False),
    "plec": pa.Column(str, checks=pa.Check.isin(['K', 'M']), nullable=False),
    "tempo_5km": pa.Column(str, checks=pa.Check.str_matches(r'^\d{1,2}:\d{2}$'), nullable=False),
})

# --- Funkcje pomocnicze ---
@st.cache_resource
def get_boto_client():
    session = boto3.session.Session()
    return session.client('s3', config=Config(s3={'addressing_style': 'path'}), region_name=DO_SPACES_ENDPOINT_URL.split('//')[1].split('.')[0], endpoint_url=DO_SPACES_ENDPOINT_URL, aws_access_key_id=DO_SPACES_KEY, aws_secret_access_key=DO_SPACES_SECRET)

@st.cache_resource
def load_model_from_spaces():
    """Pobiera i wczytuje pipeline PyCaret z DigitalOcean Spaces."""
    try:
        client = get_boto_client()
        
        # Wracamy do niezawodnej metody zapisu do pliku tymczasowego,
        # poniewa≈º ≈Çadowanie z `io.BytesIO` nie jest wspierane przez `load_model` w ten spos√≥b.
        local_path_with_ext = 'downloaded_model.pkl'
        local_path_no_ext = 'downloaded_model'
        
        client.download_file(DO_SPACES_BUCKET, MODEL_FILE_KEY, local_path_with_ext)
        
        # Przekazujemy do funkcji load_model nazwƒô pliku BEZ rozszerzenia .pkl
        model = load_model(local_path_no_ext)
        
        # Usuwamy plik tymczasowy po za≈Çadowaniu modelu do pamiƒôci
        os.remove(local_path_with_ext)
        return model
    except Exception as e:
        st.error(f"Nie uda≈Ço siƒô za≈Çadowaƒá modelu: {e}")
        return None

def time_str_to_seconds(time_str):
    try:
        m, s = map(int, time_str.split(':'))
        return m * 60 + s
    except: return None

def format_time_from_seconds(total_seconds):
    hours = int(total_seconds // 3600)
    minutes = int((total_seconds % 3600) // 60)
    seconds = int(total_seconds % 60)
    return f"{hours:02}:{minutes:02}:{seconds:02}"

def extract_data_with_llm(user_input):
    """U≈ºywa LLM do ekstrakcji danych z tekstu u≈ºytkownika."""
    trace = None
    if langfuse:
        trace = langfuse.trace(
            name="data-extraction",
            input={"user_description": user_input}
        )

    if not OPENAI_API_KEY:
        st.error("Klucz API OpenAI nie jest skonfigurowany.")
        return None
    system_prompt = """
    Jeste≈õ ekspertem w analizie tekstu. Twoim zadaniem jest wyekstrahowanie trzech informacji z tekstu podanego przez u≈ºytkownika: wieku, p≈Çci oraz tempa biegu na 5km.
    Zwr√≥ƒá odpowied≈∫ wy≈ÇƒÖcznie w formacie JSON.
    - Wiek (`wiek`) powinien byƒá liczbƒÖ ca≈ÇkowitƒÖ.
    - P≈Çeƒá (`plec`) powinna byƒá jednƒÖ z dw√≥ch warto≈õci: 'M' (mƒô≈ºczyzna) lub 'K' (kobieta).
    - Tempo na 5km (`tempo_5km`) powinno byƒá w formacie "MM:SS".
    Je≈õli kt√≥rej≈õ informacji brakuje, ustaw dla niej warto≈õƒá null.
    """
    try:
        response = openai.chat.completions.create(model="gpt-3.5-turbo-0125", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_input}], response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        if trace:
            trace.update(output=result)
        return result
    except Exception as e:
        if trace:
            trace.update(output={"error": str(e)})
        st.error(f"B≈ÇƒÖd podczas komunikacji z OpenAI: {e}")
        return None

# --- G≈Ç√≥wna aplikacja Streamlit ---
st.set_page_config(page_title="Szacowanie Czasu P√≥≈Çmaratonu", layout="wide")

st.title("üèÉ‚Äç‚ôÇÔ∏è Estymator Czasu Uko≈Ñczenia P√≥≈Çmaratonu")
st.markdown("Opisz siebie, a my oszacujemy Tw√≥j czas! Podaj sw√≥j **wiek**, **p≈Çeƒá** oraz **≈õrednie tempo na 5 km**.")

# --- ZMIENIONY OBRAZEK ---
# U≈ºywamy ≈õcie≈ºki do "surowego" pliku na GitHubie.
st.image("https://mod-9-homework.fra1.digitaloceanspaces.com/Image_19f2o619f2o619f2.png", caption="Walczymy o nowe rekordy!", use_column_width=True)


pipeline = load_model_from_spaces()

user_description = st.text_area("Przedstaw siƒô:", "Cze≈õƒá, mam 33 lata, jestem mƒô≈ºczyznƒÖ. Biegam 5km w 24 minuty i 15 sekund.", height=100)

if st.button("Szacuj czas", type="primary"):
    if not user_description:
        st.warning("Proszƒô, opisz siebie w polu tekstowym.")
    elif pipeline is None:
        st.error("Model predykcyjny nie jest dostƒôpny. Skontaktuj siƒô z administratorem.")
    else:
        with st.spinner("Analizujƒô Twoje dane i liczƒô..."):
            extracted_data = extract_data_with_llm(user_description)
            if not extracted_data:
                st.error("Nie uda≈Ço siƒô przetworzyƒá Twojego opisu.")
            else:
                st.subheader("ü§ñ Dane wyekstrahowane przez AI:")
                st.json(extracted_data)
                try:
                    validation_df = pd.DataFrame([extracted_data])
                    llm_output_schema.validate(validation_df)
                    st.info("Dane wej≈õciowe poprawne. Przystƒôpujƒô do predykcji.")
                    
                    wiek = extracted_data["wiek"]
                    plec = extracted_data["plec"]
                    tempo_5km_str = extracted_data["tempo_5km"]
                    czas_5km_s = time_str_to_seconds(tempo_5km_str)
                    tempo_1km_s = czas_5km_s / 5

                    # --- OPTYMALIZACJA PAMIƒòCI ---
                    # Definiujemy bardziej oszczƒôdne typy danych dla DataFrame'u.
                    input_data = {
                        'wiek': [wiek], 
                        'plec': [plec], 
                        'tempo_5km_s_na_km': [tempo_1km_s]
                    }
                    input_df = pd.DataFrame(input_data).astype({
                        'wiek': 'int16',
                        'plec': 'category',
                        'tempo_5km_s_na_km': 'float32'
                    })
                    
                    predictions = predict_model(pipeline, data=input_df)
                    prediction_s = predictions['prediction_label'].iloc[0]
                    predicted_time_str = format_time_from_seconds(prediction_s)

                    st.success("Oszacowanie gotowe!")
                    st.metric(label="Przewidywany czas netto na mecie p√≥≈Çmaratonu", value=predicted_time_str)

                except SchemaError as err:
                    st.error(f"B≈ÇƒÖd walidacji danych: {err.failure_cases['failure_case'][0]}")
                except Exception as e:
                    st.error(f"WystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd: {e}")

st.markdown("---")
st.info("Aplikacja wykorzystuje najlepszy model wybrany automatycznie przez PyCaret (AutoML) oraz model LLM (OpenAI GPT-3.5) do analizy tekstu.")
